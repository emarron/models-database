INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Manga109Attempt', 'Kingdomakrillic', '4', null, 'Anime / Manga', null, 4, null, null, 100, 'RRDB_PSNR_x4', 'Manga109', 'Drawing', 'Manga / Anime', 'http://www.mediafire.com/file/w3jujtm752hvdj1/Manga109Attempt.pth.zip/file', 1);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Falcon Fanart', 'LyonHrt', '4', null, 'Anime / Manga', 125000, 8, 128, null, 3393, 'RRDB_PSNR_x4', 'Falcon Fanart', 'Drawing', 'Manga / Anime', 'https://drive.google.com/open?id=1bqyG9llxkJ6i6MJTaNUiSgSXtrlPi0d7', 2);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('WaifuGAN v3', 'DinJerr', '4', null, 'Anime / Manga', 30000, 2, 128, null, 173, 'Manga109v2', 'CG-Painted Anime', 'Drawing', 'Manga / Anime', 'https://1drv.ms/u/s!Aip-EMByJHY20wpGoLuSRzjdqh0T', 3);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('De-Toon', 'LyonHrt', '4', null, 'Toon Shading / Sprite', 225000, 8, 128, 525, 7117, 'RRDB_PSNR_x4', 'Custom (Cartoon-style Photos)', 'Drawing', 'Manga / Anime', 'https://drive.google.com/open?id=1uJvdx3g3GEY0VxMnHb0ItBvoc6pmGvuH', 4);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DigiPaint', 'TheAtheistGod', '4', 'CC0', 'Digital Art Upscaler', 35000, 6, 128, 6, 48493, '4xfalcoon300(manga)', 'Custom (Digital Art, Material Studies)', 'Drawing', 'Manga / Anime', 'https://drive.google.com/open?id=103MX2bvd3GW0MYpC53ABU5VYY6v1t99Y', 5);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DeviantPixelHD', 'Raulsangonzalo', '4', 'non Commercial', 'Digital Art Upscaler', 250000, 16, 128, 1327, 2792, 'RRDB_PSNR_x4', 'Digital Art from Deviant Art', 'Drawing', 'Manga / Anime', 'https://drive.google.com/file/d/114yFJKeYCcr6st7aNNo9FJ8wDbEzLpdz/view?usp=sharing', 6);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('FireAlpha', 'BlueAmulet', '4', 'CC BY-NC 4.0', 'Artwork with Transparency (Alpha)', 1285000, null, 128, null, 104000, 'None', 'Fire Emblem Artwork with Transparency', 'Drawing', 'Manga / Anime', 'https://drive.google.com/open?id=192Mw2_yUwCgqt3tAJ2sRxZ8hYHe4CKrZ', 7);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Comic Book', 'LyonHrt', '4', null, 'Comics / Drawings', 115000, 8, 128, 592, 1548, 'none (no interpolation)', 'Custom (Spider-Man)', 'Drawing', 'Cartoon / Comic', 'https://drive.google.com/open?id=1qjpxp8z4FGLZxieUDEVKd6FDum-8vpvJ', 8);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DigitalFrames 1.0', 'Klexos', '4', null, 'Digital Animation', 1060000, 15, 128, 96.275, 2500, 'RRDB_PSNR_x4', 'Digital Cartoon Images', 'Drawing', 'Cartoon / Comic', 'https://mega.nz/#!dg4UzaCJ!dFQ0RdoeCWOypoaf2MGwCru1afArBB0yuYFDFRCfJ74', 9);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DigitalFrames 2.0', 'Klexos', '4', null, 'Digital Animation', 905000, 27, 128, 7, 1636, 'RRDB_PSNR_x4', 'Digital Cartoon Images', 'Drawing', 'Cartoon / Comic', 'https://mega.nz/#!twxxWQTT!OjPL0o9sq2MM6Flac1shLo9CvE33P9mKKF73OMT-j2I', 10);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DigitalFrames 2.1', 'Klexos', '4', null, 'Digital Animation', 230000, 27, 128, 2, 1800, 'DigitalFrames 2.0', 'Digital Cartoon Images', 'Drawing', 'Cartoon / Comic', 'https://drive.google.com/open?id=1I_qK_O123BBYiFbFOMSz8Lr3ILCd9WLb', 11);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('FatalimiX', 'Twittman', '4', 'MPLv2', 'Comics and Cartoon Style Images', 260000, 10, 128, 31, 79000, '4x_Fatality_MKII_90000_G_02.pth', 'Digital Comics', 'Drawing', 'Cartoon / Comic', 'https://de-next.owncube.com/index.php/s/jYnFtncarkBmpcF', 12);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('SpongeBob', 'Joey', '4', null, 'Cartoons & SpongeBob Games', 235000, 20, 128, 585, 8000, '4xESRGAN', 'Spongebob Season 11 (Scene-detected frames from random episodes)', 'Drawing', 'Cartoon / Comic', 'https://drive.google.com/open?id=1dT7Pw0iwPkQC4-rWriibrVLuA3KS3pS4', 13);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('SpongeBob v6', 'Joey', '4', null, 'Cartoons', 190000, 20, 128, null, 4803, '4xESRGAN', 'Spongebob Season 11 (1 frame of every scene, downscaled 50% with nearest neighbor)', 'Drawing', 'Cartoon / Comic', 'https://drive.google.com/open?id=1NHuNF36dp_myvPH__IesJ5x6GuppUwS6', 14);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Spongebob v6 De-Quantize', 'Joey', '4', null, 'Quantized Cartoons', 90000, 20, 128, null, 4803, '4x Spongebob v6', 'Spongebob Season 11 (1 frame of every scene, downscaled 50% with nearest neighbor)', 'Drawing', 'Cartoon / Comic', 'https://drive.google.com/open?id=1HFA1e75QvdostGAZVPBxFHtkiru5gLPa', 15);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Spongebob v6 Deblur', 'Joey', '4', null, 'Cartoons', 65000, 20, 128, null, 4803, '4x Spongebob v6', 'Spongebob Season 11 (1 frame of every scene, downscaled 50% with nearest neighbor)', 'Drawing', 'Cartoon / Comic', 'https://drive.google.com/open?id=1geNLDAnQzLadMvvoRLhVy4MXhQf5t8JP', 16);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Xbrz', 'LyonHrt', '4', null, 'xbrz Style Pixel Art Upscaler', 90000, 8, 128, 368, 1897000, 'RRDB_PSNR_x4', 'Custom (xbrz up-scaled)', 'Pixel Art', null, 'https://drive.google.com/open?id=1LFd4BqZ2N8p21JzjLX6hGdm7RpVIkH7s', 17);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Xbrz+DD', 'LyonHrt', '4', null, 'Dithered xbrz Style Pixel Art Upscaler', 90000, 8, 128, 470, 1523000, 'xbrz', 'Custom (De-dithered xbrz)', 'Pixel Art', null, 'https://drive.google.com/open?id=1VDbjRii9zyyUhyqnQd5H8OP8d3AuwjTe', 18);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('ScaleNX', 'LyonHrt', '4', null, 'scalenx Style Pixel Art Upscaler', 80000, 8, 128, 599, 1070000, 'RRDB_PSNR_x4', 'Custom (scalenx up-scaled from retroarch shader)', 'Pixel Art', null, 'https://drive.google.com/open?id=1jE2le5Lsab-AcMUMm0Zr9L-OvFNhnRAG', 19);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Fatality', 'Twittman', '4', 'MPLv2', 'Dithered Sprites', 265000, 10, 128, 160, 197000, 'Face', null, 'Pixel Art', null, 'https://de-next.owncube.com/index.php/s/gPjswdm6gCegQdz', 20);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Rebout', 'LyonHrt', '4', null, 'Character Sprites', 325000, 8, 128, 106, 23808000, 'Detoon', 'Custom (Prepared sprites from kof 94 rebout)', 'Pixel Art', null, 'https://cloud.owncube.com/s/24ayg3cmpW3zNza', 21);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Lady0101', 'DinJerr', '4', null, 'Painting Style', 340000, 4, 128, 52, 7000, 'WaifuGAN v3', 'CG-Painted Pinups and Landscapes', 'Pixel Art', null, 'https://1drv.ms/u/s!Aip-EMByJHY200rP1TW3aAdb2dkZ?e=enlvAO', 22);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Faithful 2x', 'Joey', '2', 'CC0', 'General Small Pixel Textures', 130000, 80, 32, 3713, 2858000, 'Private model trained from 2xESRGAN', 'Faithful 32x32 (HR) / default Minecraft 1.13 and 1.14 (LR)', 'Pixel Art', null, 'https://drive.google.com/open?id=1BzT-KwUBiZzACxGdIN6w930aOVvvfhg7', 23);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('FArtDIV3 Suite', 'DinJerr', '4', null, 'Pixels to Digital Painting', 700000, 4, 128, 100, 10000, 'ArtStation1337', 'DIV2K, FatalityFaces, ArtStation Paintings', 'Pixel Art', null, 'https://1drv.ms/u/s!Aip-EMByJHY22BhfdJ1Epkfc3ugq?e=yVfXkz', 24);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Box', 'buildist', '4', 'GNU GPLv3', 'Realistic', 390000, 8, 192, 268, 11577000, 'PSNR model from same data', 'Flickr2K, Div2K, OST', 'Photorealism', 'Misc', 'https://drive.google.com/file/d/1KToK9mOz05wgxeMaWj9XFLOE4cnvo40D/view?usp=sharing', 25);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Deoldify', 'TheAtheistGod', '4', 'CC0', 'B/W Photo Restoration', 790000, 16, 128, null, 2931000000, 'Falcon Fanart (?)', 'ADE20K, DIV2K, Library of Congress', 'Photorealism', 'Misc', 'https://drive.google.com/open?id=1-mxmDF1Dh-PnQqRz_PeCrvsTkHjYCbi3', 26);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Ground', 'ZaphodBreeblebox', '4', null, 'Ground Textures', 305000, null, 128, null, null, null, 'Custom (Ground Textures Google)', 'Photorealism', 'Misc', 'https://drive.google.com/file/d/1dGmhHUPmb3lO9buX_Bt2nq97Nk5MCTb4/view', 27);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Misc', 'Alsa', '4', 'GNU GPLv3', 'Surface Textures', 220000, 32, 128, 338, 20797000, 'Manga109Attempt', 'Custom (Photos)', 'Photorealism', 'Misc', 'https://mega.nz/#!KmpAXaJb!MoWN4XArM9n1xZEyeyS9Tt9yQkYcDvbZIszHTNzfZlo', 28);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Trixie', 'LyonHrt', '4', null, 'Star Wars', 275000, 8, 192, 87, 19814000, 'None', null, 'Photorealism', 'Character / Faces', 'https://drive.google.com/file/d/1HIBRKFs7s-XhpN1p7rwAWcMTHwFRqn3n/view', 29);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Face Focus', 'LyonHrt', '4', null, 'Face De-blur', 275000, 8, 192, 455, 4157000, 'RRDB_PSNR_x4', 'Custom (Faces)', 'Photorealism', 'Character / Faces', 'https://drive.google.com/open?id=19ICMKNuS4PbhmtA7Be9lUE6v8NHDDEzP', 30);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Face', 'Twittman', '4', null, 'Face Upscaling', 250000, 10, 128, 967, 3765000, '4xESRGAN', 'Custom (Faces)', 'Photorealism', 'Character / Faces', 'https://de-next.owncube.com/index.php/s/YbAqNMMTtxrajF6', 31);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Face-Ality V1', 'Twittman', '4', 'MPLv2', 'Face Upscaling', 310000, 10, 128, 257, 13300, '4x_Faces_04_N_180000_G.pth', 'Custom (Faces)', 'Photorealism', 'Character / Faces', 'https://de-next.owncube.com/index.php/s/mZRG4HB3KdP2iP6', 32);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('TGHQFace8x', 'Torrentguy', '8', 'GNU GPL3', 'Face Upscaling', 500000, 8, 128, 54, 70000, '8xESRGAN', 'Flickr Cropped Faces', 'Photorealism', 'Character / Faces', 'https://drive.google.com/open?id=1OyOJIW224hBhb-aTCbuUQb0qzKmE4oH6', 33);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Map', 'LyonHrt', '4', null, 'Map / Old Paper with Text', 120000, 8, 192, 361, 2311, 'none', 'Custom (Scans)', 'Specialized', null, 'https://drive.google.com/open?id=1xPzqzTG5L6y5I0U3W0oQjexwGF5zfG32', 34);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Forest', 'LyonHrt', '4', null, 'Wood / Leaves', 160000, 8, 192, 590, 2200, 'none', 'Custom (?)', 'Specialized', null, 'https://drive.google.com/open?id=12fR-pWw6YL2ZbS6EDvrAeOVoQHWkWl5L', 35);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Skyrim Armory', 'Alsa', '4', 'GNU GPLv3', 'Armor, Clothes, Weapons', 80000, 26, 128, 2600, 800, 'Manga109Attempt', 'Skyrim Mod Textures', 'Specialized', null, 'https://mega.nz/#!bmBg2KaD!4BbOLPoY2dLbMywmrfPN4f0CvSU3D7aAFq_KbQPeJMo', 36);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Skyrim Wood', 'Laeris', '4', null, 'Wood', 75000, null, null, null, null, null, null, 'Specialized', null, 'https://drive.google.com/file/d/1waC7a63nh5qkrLQe95sMcN4HRpaqhD9r/view', 37);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Skyrim Misc', 'Deorder', '4', null, 'Skyrim Diffuse Textures', 105000, null, 128, null, null, null, null, 'Specialized', null, 'https://drive.google.com/file/d/1RjVWNUFtVyz4ykqu6Pm9wmO03pPEBGqg/view', 38);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Fallout 4 Weapons', 'Bob', '4', null, 'Fallout Weapon Diffuse Textures', 120000, 13, 128, 2973, 532, 'Manga109Attempt', 'Fallout 4 HD DLC (Weapon Diffuse Textures)', 'Specialized', null, 'https://1drv.ms/u/s!AiWox1lAWLoTg1bUeJouJNOFZ_Jj', 39);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Fallout Weapons V2', 'Bob', '4', null, 'Textures, Mostly Metals', 180000, 13, 128, 1190, 1999, 'Fallout 4 Weapons', 'Fallout 4 HD DLC(Weapon, Armor, Clothes, Vehicle, Interior, Architecture Diffuse Textures', 'Specialized', null, 'https://1drv.ms/u/s!AiWox1lAWLoThANuXjxIR-hqA6os', 40);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Normal Maps', 'Alsa', '4', 'GNU GPLv3', 'Normal Maps', 36000, 27, 128, null, null, 'Normal Maps - Skyrim artifacted', 'Custom (Normal Maps)', 'Texture Maps', 'Normal Maps', 'https://mega.nz/#!Sq52DIQD!v01R93hb8Je0_8aaXLiZwKzOslDv7-FEri5_FW7H-Pw', 41);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Normal Maps - Skyrim artifacted', 'Deorder', '4', null, 'Skyrim Normal Maps', 145000, null, 128, null, null, null, 'Skyrim Normal Maps', 'Texture Maps', null, 'https://drive.google.com/file/d/14eWzh-AG6BsXX3tSiPgfQKs_zPHDOwI7/view', 42);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Skyrim Alpha', 'Deorder', '4', null, 'Alpha Channel', 105000, null, 128, null, null, null, 'Skyrim Alpha Channels', 'Texture Maps', null, 'https://drive.google.com/file/d/1trYs4AuC9s2JWAbryHdNyy5cgYV-V8cH/view', 43);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Fatality DeBlur', 'Twittman', '1', 'MPLv2', 'Deblurring', 270000, 1, 128, 4, 41000, '1x_DeJpeg_Fatality_01_175000_G.pth', 'Custom (Anime, Manga, Photos)', 'Artifact Removal', 'Blur', 'https://de-next.owncube.com/index.php/s/aAojXwLTPZto8rP', 44);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('LADDIER1', 'Alexander Syring', '4', null, 'Noise, Grain, Box / Lens / Gaussian Blur Removal', 282000, 8, 128, null, 12700, 'RRDB_ESRGAN_x4.pth', 'Custom (Nirvana, some of other images)', 'Artifact Removal', 'Blur', 'https://drive.google.com/file/d/1GoUY7t5kE0Ubi-NDvlMB8lUs-_u_f6tS/view?usp=sharing', 45);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (0-20%) A', 'Alsa', '1', 'GNU GPLv3', 'JPG Compression Removal', 178000, 2, 128, 52, 6230, 'JPG (20-40%)', 'Custom (Photos, Manga)', 'Artifact Removal', 'JPG Compression', 'https://mega.nz/#!7io2gSQR!UB9u2k51daixTgC2H0LdOWzNlkDyIDHwxBX4BVY2J3k', 46);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (0-20%) B', 'BlueAmulet', '1', 'CC BY-NC 4.0', 'JPG Compression Removal', 610000, 1, 128, 11, 52789, 'JPG (20-40%)', 'Custom (CC0 Textures)', 'Artifact Removal', 'JPG Compression', 'https://drive.google.com/file/d/1maYmC5yyzWCC42X5O0HeDuepsLFh7AV4/view', 47);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (20-40%) A', 'Alsa', '1', 'GNU GPLv3', 'JPG Compression Removal', 141000, 2, 128, 42, 6230, 'JPG (40-60%)', 'Custom (Photos, Manga)', 'Artifact Removal', 'JPG Compression', 'https://mega.nz/#!OzpFHYAD!0swA_J18bSygyVgMHac3P4kkBx6ZYUHNnL9qXhiu-9I', 48);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (20-40%) B', 'BlueAmulet', '1', 'CC BY-NC 4.0', 'JPG Compression Removal', 535000, 1, 128, 10, 52789, 'JPG (40-60%)', 'Custom (CC0 Textures)', 'Artifact Removal', 'JPG Compression', 'https://drive.google.com/file/d/1AjVnJCne4_JNYKGfzeogNxXo5zXMCGLe/view', 49);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (40-60%) A', 'Alsa', '1', 'GNU GPLv3', 'JPG Compression Removal', 100000, 2, 128, 31, 6500, 'JPG (60-80%)', 'Custom (Photos, Manga)', 'Artifact Removal', 'JPG Compression', 'https://mega.nz/#!Kr5Q1C7C!yq4910SjvAyMS_40IhrOsShA21OXdP8rxfiMsEuYbW8', 50);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (40-60%) B', 'BlueAmulet', '1', 'CC BY-NC 4.0', 'JPG Compression Removal', 550000, 1, 128, 10, 52789, 'JPG (60-80%)', 'Custom (CC0 Textures)', 'Artifact Removal', 'JPG Compression', 'https://drive.google.com/file/d/1lgpo60okKC_9D6mzymHOvwdJDsOqxi7j/view', 51);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (60-80%) A', 'Alsa', '1', 'GNU GPLv3', 'JPG Compression Removal', 91000, 2, 128, 27, 6500, 'JPG (80-100%)', 'Custom (Photos, Manga)', 'Artifact Removal', 'JPG Compression', 'https://mega.nz/#!6j4RRQBD!3CX7XN9ZEAeWR3aXBAsDRpxSfKbM8zR1N9GXgbP38Ig', 52);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (60-80%) B', 'BlueAmulet', '1', 'CC BY-NC 4.0', 'JPG Compression Removal', 545000, 1, 128, 10, 52789, 'JPG (80-100%)', 'Custom (CC0 Textures)', 'Artifact Removal', 'JPG Compression', 'https://drive.google.com/file/d/1V2PTYzMMDIB7NNCp-ZXhIf26a0xHO2b2/view', 53);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (80-100%) A', 'Alsa', '1', 'GNU GPLv3', 'JPG Compression Removal', 162000, 2, 128, 51, 6500, 'BC1 take 1', 'Custom (Photos, Manga)', 'Artifact Removal', 'JPG Compression', 'https://mega.nz/#!2uxwRYYT!2KgAsRac70jqYYXyOvQ5HSd4ipoqC0WGB4Md2Su_OM8', 54);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG (80-100%) B', 'BlueAmulet', '1', 'CC BY-NC 4.0', 'JPG Compression Removal', 550000, 1, 128, 10, 52789, 'BC1 take 1', 'Custom (CC0 Textures)', 'Artifact Removal', 'JPG Compression', 'https://drive.google.com/file/d/17ocFMDz4jfYH73mT_4i1099JCGVnOHd2/view', 55);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('JPG PlusULTRA', 'Twittman', '1', null, 'JPG Compression Removal', 130000, 1, null, 150, 937, 'Failed Attempts', 'Custom (Manga)', 'Artifact Removal', 'JPG Compression', 'https://de-next.owncube.com/index.php/s/jetoMQkKNLfRkYY', 56);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DeJpeg Fatality PlusULTRA', 'Twittman', '1', 'MPLv2', 'JPG Compression Removal', 200000, 1, 128, 5, 26000, '1x_DeJpeg_Fatality_01_200000_G.pth', 'Real Life, Manga, Digital Text', 'Artifact Removal', 'JPG Compression', 'https://de-next.owncube.com/index.php/s/w82HLrLWmWi4SQ5', 57);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('BC1 smooth 2.0', 'BlueAmulet', '1', 'CC BY-NC 4.0', 'BC1 Compression Removal', 1000000, 20, 32, 4184, 4767, 'none (no interpolation)', 'Custom (? including normal maps)', 'Artifact Removal', 'DDS Files with BC1 / DXT1, BC3 / DXT5 Compression', 'https://drive.google.com/open?id=1LHplsPRqhmjR28jGgRlEekeP_bvx3nUC', 58);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('BC1 free 1.0', 'Alsa', '1', 'GNU GPLv3', 'BC1 Compression Removal', 400000, 2, 128, 26, 28985, 'BC1 take 2', 'Custom (Just about everything)', 'Artifact Removal', 'DDS Files with BC1 / DXT1, BC3 / DXT5 Compression', 'https://mega.nz/#!qjYGXahZ!_y98olCWVgRXFZkApNv2Pfm7SrLGm4oC-_gEC7UYZAo', 59);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('BC1 restricted v1.0', 'Alsa', '1', 'GNU GPLv3', 'BC1 Compression Removal', 100000, 2, 128, 111, 1800, 'Failed Attempts', 'Custom (Photos)', 'Artifact Removal', 'DDS Files with BC1 / DXT1, BC3 / DXT5 Compression', 'https://mega.nz/#!emAAQa6B!xItl6e7WIyq1ZbXXWtLaKn7M2it7j8Rx_-wvxDjWdQQ', 60);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('BC1 restricted v2.0', 'Alsa', '1', 'GNU GPLv3', 'BC1 Compression Removal', 261000, 2, 128, 106, 4700, 'JPG (0-20%)', 'Custom (Photos / Manga)', 'Artifact Removal', 'DDS Files with BC1 / DXT1, BC3 / DXT5 Compression', 'https://mega.nz/#!r2hEAAAb!zdk-Ka6VCqVnKThtfJVYM0NnVBSUyeqsjYs-NgKjLkc', 61);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Cinepak', 'Twittman', '1', null, 'Cinepak, msvideo1, Roq Compression Removal', 200000, 1, 128, 21, 8000, 'none (no interpolation)', 'Custom (Manga)', 'Artifact Removal', 'Cinepak, msvideo1, Roq', 'https://de-next.owncube.com/index.php/s/wKjLmYsq7M5JAmx', 62);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('Cinepak_alt', 'buildist', '1', 'GNU GPLv3', 'Cinepak Compression Removal', 240000, 1, 128, 92, 2640, 'none (no interpolation)', 'Flickr2K', 'Artifact Removal', 'Cinepak, msvideo1, Roq', 'https://drive.google.com/open?id=1TMhjBAKVuDivz7FrAt-Qu7wufEJV6VUq', 63);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DeDither', 'Alsa', '1', 'GNU GPLv3', 'De-dithering', 127000, 2, 128, 53, 4700, 'JPG (0-20%)', 'Custom (Photos / Manga)', 'Artifact Removal', null, 'https://mega.nz/#!2jA1lY4D!HIrqgTbJt2AyQ12vKXLaNqZXIPnQrG4TfCJ7wesiEz0', 64);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('1x_ordered_dither', 'buildist', '1', 'GNU GPLv3', 'Ordered De-dithering', 280000, 16, 128, null, 8000, 'none (no interpolation)', 'Flickr2K, OST dithered with GIMP', 'Artifact Removal', 'Dithering', 'https://drive.google.com/open?id=1-F1YAUmuDAnu1CA3JC4z35Xq0HLs-MRx', 65);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('DeSharpen', 'loinne', '1', null, 'De-sharpens Oversharpening', 310000, 1, 128, 48, 3000, 'Failed Attempts', 'Custom (?)', 'Artifact Removal', 'Over-Sharpening', 'https://mega.nz/#!qRZD3SLL!RqP7cISIcoW5YakPya9CXEWSEHWqUSKdWLQSdYKGa14', 66);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('AntiAliasing', 'Twittman', '1', null, 'Smooths Pixelated Edges', 200000, 1, 128, 440, 656, 'none (no interpolation)', 'Custom (?)', 'Artifact Removal', 'Aliasing', 'https://de-next.owncube.com/index.php/s/mmYCcK4H3rQQR5Y', 67);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('normal generator', 'LyonHrt', '1', null, 'Diffuse to Normal', 215000, 1, 128, 45, 4536, 'none (no interpolation)', 'Custom (?)', 'Image Generation', 'Texture Maps', 'https://drive.google.com/file/d/1uksv1uyyZjQcU4567OrfU0w2NECcG8dY/view', 68);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('1xESRGAN', 'victorca25', '1', null, 'Pretrained Model', null, 1, 128, null, 65000, 'RRDB_ESRGAN_x4.pth', 'DIV2K, Flickr2K, GOPRO', 'Pretrained models for different scales', null, 'https://mega.nz/#!D940CAKR!-BAx7tSj1CgeopGkaMW31VuPsC3hvNBL35TEVAj4LIo', 69);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('2xESRGAN', 'victorca25', '2', null, 'Pretrained Model', null, 4, 128, null, 65000, 'RRDB_ESRGAN_x4.pth', 'DIV2K, Flickr2K, GOPRO', 'Pretrained models for different scales', null, 'https://mega.nz/#!vtgSWKQT!K7Asn2zKe4N70R2aV89KEMTKhH3aiyGAAiuQDJF09qs', 70);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('4xESRGAN', 'victorca25', '4', null, 'Pretrained Model', null, 8, 128, null, 65000, 'RRDB_ESRGAN_x4.pth', 'DIV2K, Flickr2K, GOPRO', 'Pretrained models for different scales', null, 'https://mega.nz/#!uhAVEaAA!qfwIQ44Ba3rXMAb2-M3aM3zFBCwzmyQ64IO_0O-csJE', 71);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('8xESRGAN', 'victorca25', '8', null, 'Pretrained Model', null, 16, 128, null, 65000, 'RRDB_ESRGAN_x4.pth', 'DIV2K, Flickr2K, GOPRO', 'Pretrained models for different scales', null, 'https://mega.nz/#!6kwQiCCS!v2uN8R44vVrlzmSqffGaCnzgogkPhhl67myJbuG45SA', 72);
INSERT INTO upscale_wiki.export_models2 (Name, Author, Scale, License, Purpose, Iterations, `Batch Size`, `HR Size`, Epoch, `Dataset Size`, `Pre-trained Model`, Dataset, Category, Subcategory, Link, `index`) VALUES ('16xESRGAN', 'victorca25', '16', null, 'Pretrained Model', null, 16, 128, null, 65000, 'RRDB_ESRGAN_x4.pth', 'DIV2K, Flickr2K, GOPRO', 'Pretrained models for different scales', null, 'https://mega.nz/#!btwEXAoI!nNxWI89OdQCEkcRoPEFwj6GoFN8uzZyZFaCn1wbhzKY', 73);